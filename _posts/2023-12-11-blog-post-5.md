---
title: 'A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks: An Explainer'
date: 2023-12-11
permalink: /posts/2023/12/ood-baseline-explainer/
tags:
  - OOD Detection
  - Machine Learning
  - Deep Learning
---

The OOD baseline paper titled _"A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks"_ is one of the most important research paper in OOD detection literature. Though the paper is not mathematically and technically heavy, it certainly has some concepts that might not be straightforward for beginners. The discussion and/or tutorial of the paper has been [lacking](https://www.reddit.com/r/MachineLearning/comments/13wcopl/d_has_anyone_read_an_old_paper_called_baseline/) in the internet. Hence, to help the beginners dive into the field of out-of-distribution detection and make it easier for beginners to fully understand the concepts of the paper, I have written an explainer blog. 

# What is the paper trying to convey?
This is the first question we need to answer. The paper is trying to convey a few important things about predictions of a softmax function.
1. The prediction probability outputted by the softmax function to a bunch of classes can not be literally interpreted as a probability. If a cat/dog classifier predicts 90% probability for cat, it does not mean 9 out of 10 times the ground truth would be cat. Instead, it gives a proxy value of confidence the model has in its prediction.
2. However, the softmax probability can be useful to determine two things:
    - How likely the model's prediction is wrong?
    - How likely the input data is out-of-distribution?
    
    The lower value of softmax probability gives us the signal that the model might not be doing great in the example. This might be because the example is quite difficult for the model or the example might be out-of-distribution.
3. So, they see the statistics of the softmax probability of correct examples (the examples on which the model made right predictions) and wrong examples (the examples on which the model made wrong predictions). They find out that the distribution of the softmax probability is different for correct and wrong examples. They even show the statistical significance of the difference using Wilcoxon rank-sum test. So, this means we can pick some threshold which separates the distribution of correct examples and wrong examples, and then use that to reject to make predictions on _probable_ wrong examples.

